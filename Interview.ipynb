{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TA_Senior_Analyst"
      ],
      "metadata": {
        "id": "MKZvR93NbAkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Explain projects\n",
        "- what kind of time series analysis for current project\n",
        "- Probability of 5sundays in a month"
      ],
      "metadata": {
        "id": "eKrGwhVgenok"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgHhti3_w6iH"
      },
      "outputs": [],
      "source": [
        "# Find the factorial of an element n\n",
        "def factorial(n):\n",
        "\n",
        "  if n == 1: return 1\n",
        "\n",
        "  else: return n*factorial(n-1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(factorial(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt6kqhHfxQYY",
        "outputId": "a2ed6320-bafd-4ebc-a7c6-5eaebf2c213d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the list of all nearest integers to a value k\n",
        "lst = [1,3,5,7,3,10]\n",
        "\n",
        "\n",
        "'''def nearest_integers_to_k(lst, k):\n",
        "\n",
        "  min_idx = 0\n",
        "  for i in range(0, len(lst)):\n",
        "    if abs(lst[i] - k) < abs(lst[min_idx] - k):\n",
        "      min_idx = i\n",
        "\n",
        "  \n",
        "  return lst[min_idx]'''\n",
        "\n",
        "\n",
        "def nearest_integers_to_k(lst, k):\n",
        "\n",
        "  diff_lst = [abs(lst[i] - k) for i in range(len(lst))]\n",
        "\n",
        "  min_lst = []\n",
        "  min_val = diff_lst[0]\n",
        "  for i in range(len(diff_lst)):\n",
        "    if diff_lst[i] <= min_val:\n",
        "      min_val = diff_lst[i]\n",
        "      min_lst.append(diff_lst[i] ) \n",
        "\n",
        "\n",
        "  \n",
        "  return min_lst\n",
        "\n",
        "  # Soln : https://www.geeksforgeeks.org/find-k-closest-elements-given-value/"
      ],
      "metadata": {
        "id": "8V7mvq2lxcFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 6\n",
        "print(nearest_integers_to_k(lst, k))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnF9yct5xuKC",
        "outputId": "d551e9d1-fe89-46c9-c769-1401721a4483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 3, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMdmA2pz2aN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tredence"
      ],
      "metadata": {
        "id": "PBoLQVxwbGSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Round 1"
      ],
      "metadata": {
        "id": "PPtgmwoQeffh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the palindrome words in a sentence\n",
        "\n",
        "text = \"mom dad bro sis huloluh prorp\"\n",
        "\n",
        "def count_palindromes(text):\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  for word in text.split(\" \"):\n",
        "\n",
        "    start_idx, end_idx = 0, len(word) - 1\n",
        "    \n",
        "    while start_idx != end_idx:\n",
        "      if word[start_idx] != word[end_idx]: break\n",
        "      start_idx += 1\n",
        "      end_idx -= 1\n",
        "\n",
        "    if start_idx == end_idx: count += 1\n",
        "\n",
        "  return count"
      ],
      "metadata": {
        "id": "KDY-uV1XbHnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(count_palindromes(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpKHEwbTbzrN",
        "outputId": "8d0ec286-e048-46ce-bfee-c2bda8e02f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Round 2"
      ],
      "metadata": {
        "id": "Hm0nELhkcejf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TTS Tacotron 2:\n",
        "\n",
        "- Explain the kinds of data augmentation used for text\n",
        "- How did the text get converted into speech (model)\n",
        "- A bit about hyperparameter tuning, (find out which loss, metric too)\n",
        "\n",
        "Unet:\n",
        "\n",
        "- What loss function used\n",
        "- What if we use only white color cars in training and we have red color cars in the test set (I say i see this as an over fitting problem, so work on the dataset or try to train with different hyperparameters)\n",
        "- Test vs validation ?\n",
        "- why you didnt use transformers (since the whole architecture had to be replaced)\n",
        "\n",
        "General:\n",
        "\n",
        "- Bagging vs boosting, which is more likely tooverfit\n",
        "\n",
        "- How to handle missing data when it is 40 percent of the data and i have a whole column which i cant discard. (I answered predict it using available data. Wich model ? RF)\n",
        "- How can we assign more weight to feature as per customer in RF ? (I say, probably use feature weights, but not sure exactly how)\n",
        "\n",
        "NLP\n",
        "\n",
        "- What project (laughed and said im happy you did not say sentiment analysis)\n",
        "- Which embedding did you use, how glove is better than word2vec\n",
        "- How can we encode director name for movie rating prediction (I say label encoding/ pd.dummy_values but he is like how can one have more importance than the other)"
      ],
      "metadata": {
        "id": "n8BWhi44cgpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prep for Round 3:\n",
        "\n",
        "- ALL ABOUT RF: Can we set weights for the trees ? to solve the problem above. Explore advanced concepts about RF; How do we use Extratrees RF model ?\n",
        "- Categorical features encoding ? How to work with NLP features better ?\n",
        "- Overfitting, hyperparameter tuning, data augmentation .. with respect to TTS"
      ],
      "metadata": {
        "id": "j0MWAaKY4-__"
      }
    }
  ]
}